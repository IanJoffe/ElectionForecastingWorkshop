{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "252d32c7",
   "metadata": {},
   "source": [
    "# Forecasting the 2022 Election: A PCS Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fbd7ce",
   "metadata": {},
   "source": [
    "### Created by Ian Joffe, Spring 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e33d22e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%store -r solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f33fca0",
   "metadata": {},
   "source": [
    "## Playing with the Beta Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1805d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "beta = 1\n",
    "\n",
    "x = np.linspace(0,1,200)\n",
    "y = stats.beta.pdf(x, alpha, beta)\n",
    "plt.plot(x, y);\n",
    "plt.title(\"Beta(\" + str(alpha) + \", \" + str(beta) + \")\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38ed610",
   "metadata": {},
   "source": [
    "### Conceptual Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8bf99e",
   "metadata": {},
   "source": [
    "What is the affect of increasing $\\alpha$? What is the affect of increasing $\\beta$? What happens if we set $\\alpha = \\beta$ and increase both? For $\\alpha, \\beta > 1$, approximately where is the distribution centered?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c2e4de",
   "metadata": {},
   "source": [
    "## Gathering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d4d108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following cells must be run in order, once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548aa0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use fivethirtyeight's generic ballot polling average for our forecast\n",
    "polls = pd.read_csv(\"generic_topline_historical.csv\")[[\"modeldate\", \"dem_estimate\", \"rep_estimate\"]]\n",
    "polls[\"dem_lead\"] = polls[\"dem_estimate\"] - polls[\"rep_estimate\"]\n",
    "polls = polls.drop([\"dem_estimate\", \"rep_estimate\"], axis=1)\n",
    "polls = polls[polls[\"modeldate\"].str.slice(0,1) == \"4\"]\n",
    "print(\"All April Polls:\")\n",
    "polls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b134fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "polls[\"year\"] = polls[\"modeldate\"].str.slice(start=-4).astype(int)\n",
    "polls = polls[np.mod(polls[\"year\"], 2) == 0]\n",
    "polls = polls[polls[\"year\"] % 2 == 0]\n",
    "polls = polls.groupby(\"year\").mean()\n",
    "# I have to manually add data from 2018 and 2020 because it's from a different data set\n",
    "additional_data = pd.DataFrame({\"Year\": [2018, 2020], \"dem_lead\": [7.1093803, 7.749738]})\n",
    "additional_data = additional_data.set_index(\"Year\")\n",
    "polls = polls.append(additional_data)\n",
    "# Append the final voting margins for each year to the data set\n",
    "final_margins = [0, -1, 0, -5, -3, 8, 11, -7, 1, -6, 1, 9, 3]\n",
    "polls[\"true_result\"] = final_margins\n",
    "polls[\"dem_lead\"] = polls[\"dem_lead\"] / 100\n",
    "polls[\"true_result\"] = polls[\"true_result\"] / 100\n",
    "print(\"April Polling Averages from Midterm Years\")\n",
    "polls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9d8dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "polls_abs = polls.copy(deep=True)\n",
    "polls_abs[\"dem_lead\"] = .5 + polls[\"dem_lead\"] / 2\n",
    "polls_abs[\"true_result\"] = .5 + polls[\"true_result\"] / 2\n",
    "polls_abs = polls_abs.rename(columns={\"dem_lead\": \"dem_pct\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a5ed1c",
   "metadata": {},
   "source": [
    "## Implementing Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d536ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_reparam(x, mode, concentration):\n",
    "    return stats.beta.pdf(x, mode * (concentration - 2) + 1, (1 - mode) * (concentration - 2) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de37e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = .5\n",
    "concentration = 300\n",
    "\n",
    "x = np.linspace(0,1,200)\n",
    "y = beta_reparam(x, mode, concentration)\n",
    "plt.plot(x, y);\n",
    "plt.title(\"Beta(mode=\" + str(mode) + \", concentration=\" + str(concentration) + \")\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb48c0c",
   "metadata": {},
   "source": [
    "### Conceptual Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c54233",
   "metadata": {},
   "source": [
    "Like before, experiment with the affects of changing the mode and concentration parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9539cb8",
   "metadata": {},
   "source": [
    "### Code Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fb98eb",
   "metadata": {},
   "source": [
    "```calculate_result_probabilities``` returns a list of the probabilities of the true outcome for each election since 1996, with respect to their polling leads and a given confidence in polling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e2b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_result_probabilities(confidence):\n",
    "    true_results = polls_abs[\"true_result\"].values\n",
    "    leads = polls_abs[\"dem_pct\"].values\n",
    "    n = len(true_results)\n",
    "    return np.array([beta_reparam(...[i], ...[i], ...) for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe3d4f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run to view solution\n",
    "print(solutions[\"calculate_result_probabilities\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aab5e50",
   "metadata": {},
   "source": [
    "### Code Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b066b8",
   "metadata": {},
   "source": [
    "Say we choose some value for confidence. Design an appropriate loss function that calculates the loss for the chosen confidence over elections since 1996. Your loss function should call ```calculate_result_probabilities(confidence)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a3ade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(confidence):\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b48b9f",
   "metadata": {},
   "source": [
    "Plot the loss function for many different confidence values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706e2b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "confs = np.linspace(0, 2000, 500)\n",
    "losses = []\n",
    "for c in confs:\n",
    "    losses.append(loss(c))\n",
    "plt.plot(confs, losses);\n",
    "plt.xlabel(\"Confidence Parameter Value\");\n",
    "plt.ylabel(\"Loss\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee9b9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to view solution\n",
    "print(solutions[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1a0fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the method of finite differences to calculate the derivative of our loss function at a given confidence\n",
    "\n",
    "def finite_difference(func, x, epsilon=.0001):\n",
    "    return (func(x+epsilon) - func(x-epsilon)) / (2 * epsilon)\n",
    "\n",
    "def loss_deriv_fd(confidence, epsilon=.001):\n",
    "    return finite_difference(loss, confidence) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e1eef8",
   "metadata": {},
   "source": [
    "### Code Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2606c282",
   "metadata": {},
   "source": [
    "Implement the Gradient Descent algorithm. Line 1 randomly initializes our initial confidence. Line 2 sets the number of \"epochs,\" which is the number of times we go over all our data, calculate a new loss, and reassign ```optimal_confidence```. Line 3 sets the learning rate - you can try messing with this, but it's preset to a good value. Write one line to replace the elipses which updates ```optimal_confidence``` according to the gradient descent formula. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f4aee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_confidence = np.random.uniform(1, 100)\n",
    "epochs = 500\n",
    "learning_rate = 10\n",
    "\n",
    "optimal_confidence = initial_confidence\n",
    "for epoch in range(epochs):\n",
    "    ...\n",
    "    \n",
    "print(optimal_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905fac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(solutions[\"gradient descent\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fe43dd",
   "metadata": {},
   "source": [
    "## Implementing Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc735752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this section, we use FiveThiryEight's metrics for paritsan lean and elasticity.\n",
    "# The partisan lean metric is on the correct scale for our purpose, but the elasticity metric is normalized around 1. \n",
    "# This function takes in a FiveThirtyEight elasticity value, and applies some transformation to it to make it more useful in \n",
    "# our context. \n",
    "def elasticity_to_confidence(elasticity):\n",
    "    return 500 - 1000 * (elasticity - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7761c9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The current percent of the vote going to democrats, adapted from FiveThirtyEight's 2022 generic ballot tracker, \n",
    "# as of this morning (4/17). Recall we assume that all votes go to dem or rep, so dem_pct = 0.5 + dem_lead / 2\n",
    "current_dem_pct = .4885"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ca9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the FiveThirtyEight's data about each district. \n",
    "# Here, we apply another simplifcation. Since not all district maps have been approved, we assume the 2022 house districts\n",
    "# and their partisan leans match those of 2020. \n",
    "districts = pd.read_csv(\"partisan_leans.csv\", header=None).loc[:,[0,1,2]].rename(columns={0:\"district\", 1:\"lean\", 2:\"elasticity\"})\n",
    "print(\"The FiveThirtyEight partisan lean and elasticity of each district:\")\n",
    "districts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed4ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the scale of the lean metric to match our standard\n",
    "districts[\"lean\"] = districts[\"lean\"].str.slice(2).astype(float) * np.where(districts[\"lean\"].str.slice(stop=1) == \"D\", 1, -1) / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e337c026",
   "metadata": {},
   "source": [
    "### Code Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5346267",
   "metadata": {},
   "source": [
    "Set the values of ```mode``` and ```concentration``` for the simulation of a singular district under the beta distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb5707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_district(natl_gen_ballot, state_lean, elasticity):\n",
    "    mode = ...\n",
    "    concentration = ...\n",
    "    if mode > 1:\n",
    "        return 1\n",
    "    elif mode < 0:\n",
    "        return 0\n",
    "    else: \n",
    "        return stats.beta.rvs(mode * (concentration - 2) + 1, (1 - mode) * (concentration - 2) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23d7579",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(solutions[\"simulate_district\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1429281d",
   "metadata": {},
   "source": [
    "This is the simulation for the entire country. Note how here, the mode is set to the current generic ballot lead for democrats, and the concentration is the set to the optimal concentration we set earlier. This function calls ```simulate_district``` for each district, keeps a list of the probability of democrats winning each district, and returns the number of districts in which democrats are at least 50% likely to win. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a47b47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_country():\n",
    "    mode = current_dem_lead\n",
    "    concentration = optimal_confidence\n",
    "    natl_avg = stats.beta.rvs(mode * (concentration - 2) + 1, (1 - mode) * (concentration - 2) + 1)\n",
    "    dist_outcomes = []\n",
    "    for district in districts.iterrows():\n",
    "        dist_outcomes.append(simulate_district(natl_avg, district[1][\"lean\"], elasticity_to_confidence(district[1][\"elasticity\"])))\n",
    "    # Returns the number of seats that democrats \"win\"\n",
    "    return sum(np.array(dist_outcomes) > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7614d7e9",
   "metadata": {},
   "source": [
    "We run simulate_country ```n_simulations``` times, and make a list of the seats that democrats win each of them. In the next cell, we make a histogram of the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce1b9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_simulations = 500\n",
    "dem_seats = []\n",
    "for i in range(n_simulations):\n",
    "    dem_seats.append(simulate_country())\n",
    "dem_seats = np.array(dem_seats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f500a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dem_seats, bins=20);\n",
    "plt.axvline(218, color=\"red\", linewidth=1);\n",
    "plt.title(\"Probability of Dem Majority: \" + str(sum(dem_seats >= 218) / len(dem_seats)) + \"\\nMean Dem Seats: \" + str(int(np.mean(dem_seats))));\n",
    "plt.xlabel(\"Dem Seats\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7551bb",
   "metadata": {},
   "source": [
    "## A Much More Simple Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f167174",
   "metadata": {},
   "source": [
    "### Code Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286e546d",
   "metadata": {},
   "source": [
    "In an attempt to simplify our model, we say that the house goes whatever way the tipping point district goes. The following code block should execute this strategy rather efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947da020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the partisan lean of the tipping point district\n",
    "# Recall the we can get a list of all partisan leans with districts[\"lean\"]\n",
    "# Perhaps google a function you can apply to this list (or, more accurately, pandas series)?\n",
    "tipping_point_dist_lean = ...\n",
    "\n",
    "print(\"The tipping point district has a lean of \" + str(tipping_point_dist_lean))\n",
    "\n",
    "# Now, we plan to plug this district's mode and concentration into the beta distribution.\n",
    "# What would be use for the mode?\n",
    "tipping_point_dist_mode = ...\n",
    "\n",
    "tipping_point_dist_concentration = optimal_concentration\n",
    "\n",
    "# Convert back to the alpha/beta paramaterization and plug in to the beta distribution\n",
    "alpha = tipping_point_dist_mode * (tipping_point_dist_concentration - 2) + 1\n",
    "beta = (1 - tipping_point_dist_mode) * (tipping_point_dist_concentration - 2) + 1\n",
    "prob_dem_win = 1 - stats.beta.cdf(.5, alpha, beta)\n",
    "print(\"According to the simple model, Democrats have a \" + str(prob_dem_win) + \" chance of winning the house\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24653851",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(solutions[\"tipping_point_model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a95ff5d",
   "metadata": {},
   "source": [
    "## A Slightly More Complex Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b41589",
   "metadata": {},
   "source": [
    "### The \"Midterm Penalty\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4526c56e",
   "metadata": {},
   "source": [
    "Add the ```dem_pres``` column to the polls table, which is is 0 in general elections years, 1 if the sitting president is a democrat, and -1 if the sitting president is a republican. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cedf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "polls_abs[\"dem_pres\"] = [0, 1, 0, -1, 0, -1, 0, 1, 0, 1, 0, -1, 0]\n",
    "polls_abs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ee3c8e",
   "metadata": {},
   "source": [
    "### Code Q6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fb345e",
   "metadata": {},
   "source": [
    "Our setup for gradient descent is very similar to before, but now we have two to optimize (the confidence and the penalty) instead of one (just the confidence) like before. Loss is a function of both parameters, and it has two derivatives: one with respect to each parameter. Like before, we use the finite difference method to calculate each derivative. Complete the two finite difference functions to find each of the two derivatives. You can use a non-general version of the old univariate finite difference function as a model: \n",
    "\n",
    "```\n",
    "def finite_difference(confidence, epsilon=.0001):\n",
    "    return (loss(confidence+epsilon) - loss(confidence-epsilon)) / (2 * epsilon)\n",
    "```\n",
    "\n",
    "In each of the new functions we should be applying the epsilon transformation to one of the two parameters, and keeping the other one constant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c9bc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_result_probabilities(confidence, penalty):\n",
    "    true_results = polls_abs[\"true_result\"].values\n",
    "    leads = polls_abs[\"dem_lead\"].values\n",
    "    dem_pres = polls_abs[\"dem_pres\"].values\n",
    "    n = len(true_results)\n",
    "    # Take a look at this line\n",
    "    # Our new mode is now the generic ballot (like you set up in Code Q1) MINUS a penalty, which is applied to\n",
    "    # niether party in a general election year, and the sitting presidential party in midterm years. \n",
    "    return np.array([beta_reparam(true_results[i], leads[i] - penalty*dem_pres[i], confidence) for i in range(n)])\n",
    "\n",
    "def loss(confidence, penalty):\n",
    "    return -sum(calculate_result_probabilities(confidence, penalty) ** (1/3))\n",
    "\n",
    "def loss_deriv_wrt_confidence(confidence, penalty, epsilon=.001):\n",
    "    def finite_difference(confidence, penalty):\n",
    "        return (loss(..., ...) - loss(..., ...)) / (2 * epsilon)\n",
    "    return finite_difference(confidence, penalty)\n",
    "\n",
    "def loss_deriv_wrt_penalty(confidence, penalty, epsilon=.001):\n",
    "    def finite_difference(confidence, penalty):\n",
    "        return (loss(..., ...) - loss(..., ...)) / (2 * epsilon)\n",
    "    return finite_difference(confidence, penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3965ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(solutions[\"multivariate fd\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6657cd8d",
   "metadata": {},
   "source": [
    "Perform gradient descent. This is just a doubled version of the algorithm that you wrote earlier. We initialize *both* parameters, and then apply the update step to *both* parameters, calling each's own derivative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af39f7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_confidence = np.random.uniform(1, 100)\n",
    "initial_penalty = np.random.uniform(0, .1)\n",
    "epochs = 500\n",
    "learning_rate_confidence = 10\n",
    "learning_rate_penalty = .0001\n",
    "\n",
    "optimal_confidence = initial_confidence\n",
    "optimal_penalty = initial_penalty\n",
    "for epoch in range(epochs):\n",
    "    optimal_confidence -= learning_rate_confidence * loss_deriv_wrt_confidence(optimal_confidence, optimal_penalty)\n",
    "    optimal_penalty -= learning_rate_penalty * loss_deriv_wrt_penalty(optimal_confidence, optimal_penalty)\n",
    "    \n",
    "print(optimal_confidence)\n",
    "print(optimal_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3280cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_district(natl_gen_ballot, state_lean, elasticity):\n",
    "    mode = natl_gen_ballot + state_lean\n",
    "    concentration = elasticity\n",
    "    if mode > 1:\n",
    "        return 1\n",
    "    elif mode < 0:\n",
    "        return 0\n",
    "    else: \n",
    "        return stats.beta.rvs(mode * (concentration - 2) + 1, (1 - mode) * (concentration - 2) + 1)\n",
    "    \n",
    "def simulate_country():\n",
    "    # The only change from earlier is the following line.\n",
    "    # The midterm penalty is applied to democrats because Joe Biden is president. \n",
    "    mode = current_dem_lead - optimal_penalty\n",
    "    concentration = optimal_confidence\n",
    "    natl_avg = stats.beta.rvs(mode * (concentration - 2) + 1, (1 - mode) * (concentration - 2) + 1)\n",
    "    dist_outcomes = []\n",
    "    for district in districts.iterrows():\n",
    "        dist_outcomes.append(simulate_district(natl_avg, district[1][\"lean\"], elasticity_to_confidence(district[1][\"elasticity\"])))\n",
    "    return sum(np.array(dist_outcomes) > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c53f9d2",
   "metadata": {},
   "source": [
    "Just like before, simulate and graph the election results ```n_simulations``` times. Though you may encounter some randomness, Democrats should generally do worse in this model than earlier due to the penalty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6115b806",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_simulations = 500\n",
    "dem_seats = []\n",
    "for i in range(n_simulations):\n",
    "    dem_seats.append(simulate_country())\n",
    "dem_seats = np.array(dem_seats)\n",
    "\n",
    "plt.hist(dem_seats, bins=20);\n",
    "plt.axvline(218, color=\"red\", linewidth=1);\n",
    "plt.title(\"Probability of Dem Majority: \" + str(sum(dem_seats >= 218) / len(dem_seats)) + \"\\nMean Dem Seats: \" + str(int(np.mean(dem_seats))));\n",
    "plt.xlabel(\"Dem Seats\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2597261b",
   "metadata": {},
   "source": [
    "### Covariant Districts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1928e67",
   "metadata": {},
   "source": [
    "### Conceptual Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b85b86",
   "metadata": {},
   "source": [
    "Some distircts are likely to vote similarly to others, often based on geographic or demographic factors. Improve your model by accounting for this in the ```covariant_districts``` dictionary. Each key district maps to one or multiple value districts, which its outcomes correlate to. Using your knowledge of geography and demography (plus http://proximityone.com/cd.htm, a resource which has demographic info on congrssional districts at a table in the middle, and https://www.govtrack.us/congress/members/map, a map of US congressional districts), improve the model by accounting for covariant districts. I've already added districts from downtown NYC, Los Angeles, and Chicago - although I won't guarantee that they are actually correlated, you should check that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a5eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariant_districts = {\"CA-34\": [\"NY-12\", \"IL-7\"], \"NY-12\": [\"CA-34\", \"IL-7\"], \"IL-7\":[\"CA-34\", \"NY-12\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cd3953",
   "metadata": {},
   "source": [
    "The following code is very similar to the functions we wrote earlier - the only difference is it now accounts for the covariant districts. First, we randomize the order of the districts. Then, for each district, if there are no covariants yet we do the same as before, but if there are covariants we apply them. \n",
    "\n",
    "The ```elasticity_factor```, which is between 0 and 1, is the factor by which we multiply the elasticity by for each covariant state. It makes sense that elasticity decreases for every state that is covariant. \n",
    "\n",
    "The ```average_factor``` is applied so that if a district correlates to one other district, the mode of its beta distribution is the national generic ballot times one minus the factor, plus the covariant state times the factor. \n",
    "\n",
    "You're welcome to play with these two parameters. In a much more complex model, each covariant will have its own value for these two factors, and those values could be optimized using a method like gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ec4f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariant_state_elasticity_factor = .75\n",
    "covariant_state_average_factor = .3\n",
    "\n",
    "def simulate_district(natl_gen_ballot, district, prev_outcomes):\n",
    "    \n",
    "    def get_elasticity():\n",
    "        elasticity = elasticity_to_confidence(district[\"elasticity\"])\n",
    "        covariants = covariant_states.get(district[\"district\"][:2])\n",
    "        if covariants is not None:\n",
    "            for covariant in covariants:\n",
    "                if covariant in list(prev_outcomes.keys()):\n",
    "                    elasticity *= covariant_state_elasticity_factor\n",
    "        return elasticity\n",
    "        \n",
    "    def get_avg():\n",
    "        avg = natl_gen_ballot + district[\"lean\"]\n",
    "        covariants = covariant_states.get(district[\"district\"][:2])\n",
    "        if covariants is not None:\n",
    "            for covariant in covariants:\n",
    "                if covariant in list(prev_outcomes.keys()):\n",
    "                    avg = prev_outcomes[covariant] * convariant_state_average_factor + avg * (1-covariant_state_average_factor)\n",
    "        return avg\n",
    "            \n",
    "    mode = get_avg()\n",
    "    concentration = get_elasticity()\n",
    "    if mode > 1:\n",
    "        return 1\n",
    "    elif mode < 0:\n",
    "        return 0\n",
    "    else: \n",
    "        return stats.beta.rvs(mode * (concentration - 2) + 1, (1 - mode) * (concentration - 2) + 1)\n",
    "    \n",
    "def simulate_country():\n",
    "    mode = current_dem_lead\n",
    "    concentration = optimal_confidence\n",
    "    natl_avg = stats.beta.rvs(mode * (concentration - 2) + 1, (1 - mode) * (concentration - 2) + 1)\n",
    "    dist_outcomes = {}\n",
    "    for district in districts.iterrows():\n",
    "        dist_outcomes[district[1][\"district\"]] = simulate_district(natl_avg, district[1], dist_outcomes)\n",
    "    return sum(np.array(list(dist_outcomes.values())) > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2507041b",
   "metadata": {},
   "source": [
    "Like before, run the simulations. Since we're only applying a few covariances you probably won't notice a big difference in the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36143b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_simulations = 500\n",
    "dem_seats = []\n",
    "for i in range(n_simulations):\n",
    "    dem_seats.append(simulate_country())\n",
    "dem_seats = np.array(dem_seats)\n",
    "\n",
    "plt.hist(dem_seats, bins=20);\n",
    "plt.axvline(218, color=\"red\", linewidth=1);\n",
    "plt.title(\"Probability of Dem Majority: \" + str(sum(dem_seats >= 218) / len(dem_seats)) + \"\\nMean Dem Seats: \" + str(int(np.mean(dem_seats))));\n",
    "plt.xlabel(\"Dem Seats\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1bf4a2",
   "metadata": {},
   "source": [
    "You've now written the key components of a working model for the 2022 house election! We made a lot of assumptions and simplifications that might affect our accuracy, but all in all, our model should actually be pretty decent. Once the industry standard models (e.g. FiveThirtyEight, The Economist) come out, it'll be interesting to see how close their probabilities match up with ours."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
